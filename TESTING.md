# Testing and Trace Analysis

## Evaluation Traces

The `traces/` directory contains JSON trace files generated by E2E tests for debugging and analysis.

### Generated Files

When you run `make test-e2e`, trace files are automatically saved to `traces/`:

- `basic_evaluation_trace.json` - Single eval with tool usage
- `multiple_tools_trace.json` - Eval using multiple tools in sequence
- `batch_add_trace.json` - Addition eval from batch test
- `batch_echo_trace.json` - Echo eval from batch test
- `batch_get_user_info_trace.json` - User API eval from batch test

### Trace Structure

Each trace file contains:

```json
{
  "steps": [
    {
      "step_number": 1,
      "start_time": "2025-01-15T10:30:00Z",
      "end_time": "2025-01-15T10:30:02Z",
      "duration": 2000000000,
      "model_response": "I'll help you...",
      "stop_reason": "tool_use",
      "tool_calls": [
        {
          "tool_id": "toolu_abc123",
          "tool_name": "add",
          "start_time": "2025-01-15T10:30:01Z",
          "end_time": "2025-01-15T10:30:01.5Z",
          "duration": 500000000,
          "input": {"a": 5, "b": 3},
          "output": {"result": 8},
          "success": true
        }
      ],
      "input_tokens": 450,
      "output_tokens": 125
    }
  ],
  "grading": {
    "user_prompt": "What is 5 plus 3?",
    "model_response": "The result is 8.",
    "expected_result": "Should return 8",
    "grading_prompt": "Here is the user input: ...",
    "raw_grading_output": "{\"accuracy\": 5, ...}",
    "start_time": "2025-01-15T10:30:03Z",
    "end_time": "2025-01-15T10:30:04Z",
    "duration": 1000000000,
    "input_tokens": 300,
    "output_tokens": 50
  },
  "total_duration": 5000000000,
  "total_input_tokens": 750,
  "total_output_tokens": 175,
  "step_count": 2,
  "tool_call_count": 1
}
```

## Usage Examples

### View trace in browser
```bash
cat traces/basic_evaluation_trace.json | jq . | less
```

### Extract tool call durations
```bash
jq '.steps[].tool_calls[] | {tool: .tool_name, duration_ms: (.duration / 1000000)}' traces/basic_evaluation_trace.json
```

### Check total token usage
```bash
jq '{input_tokens: .total_input_tokens, output_tokens: .total_output_tokens, total: (.total_input_tokens + .total_output_tokens)}' traces/*.json
```

### Find slowest steps
```bash
jq '.steps | sort_by(.duration) | reverse | .[0] | {step: .step_number, duration_ms: (.duration / 1000000), tools: [.tool_calls[].tool_name]}' traces/basic_evaluation_trace.json
```

## Analysis Use Cases

1. **Debugging failures**: Examine step-by-step execution to see where things went wrong
2. **Performance optimization**: Identify slow tool calls or excessive steps
3. **Token cost analysis**: Calculate exact costs per eval
4. **Model comparison**: Compare traces from different models to see behavioral differences
5. **Audit trails**: Complete record of all interactions for compliance

## Test Fixtures

The `internal/reporting/testdata/` directory contains example trace files used for testing the reporting system. These fixtures demonstrate different evaluation scenarios and can be used with the CLI for testing.

### Example Trace Files

- `weather-forecast.json` - Successful evaluation (PASS) with 100% tool success rate
- `database-query.json` - Marginal pass (3.0 avg) with failed tool call recovery
- `api-integration-test.json` - Failed evaluation (FAIL) with authentication error
- `connection-timeout.json` - Error case with no trace data
- `simple-echo-test.json` - Evaluation without grading

### Testing with Fixtures

Generate reports from example traces:

```bash
# Single file with verbose output
./mcp-evals report --verbose \
  --trace-files internal/reporting/testdata/weather-forecast.json

# All fixtures using a loop
./mcp-evals report --verbose \
  $(for f in internal/reporting/testdata/*.json; do echo --trace-files $f; done)
```

### Fixture Format

Fixtures include the complete eval result structure:

```json
{
  "eval": {
    "name": "weather-forecast",
    "description": "Test weather API integration",
    "prompt": "Get the 5-day weather forecast for San Francisco"
  },
  "grade": {
    "accuracy": 5,
    "completeness": 5,
    "relevance": 5,
    "clarity": 4,
    "reasoning": 5,
    "overall_comments": "The response accurately uses weather API tools..."
  },
  "trace": { /* trace data */ }
}
```

## Note

Runtime trace files in `traces/` are gitignored and not committed to the repository. They're generated fresh each time you run E2E tests. Test fixtures in `internal/reporting/testdata/` are committed for testing purposes.
